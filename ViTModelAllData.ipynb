{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10136779,"sourceType":"datasetVersion","datasetId":6256151},{"sourceId":10136842,"sourceType":"datasetVersion","datasetId":6256195},{"sourceId":10136948,"sourceType":"datasetVersion","datasetId":6256266}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport h5py\nfrom transformers import ViTForImageClassification, ViTConfig\nimport torch.nn as nn\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport h5py\n\n# Define the SequenceDataset class\nclass SequenceDataset(Dataset):\n    def __init__(self, h5_file):\n        # Load the HDF5 file\n        self.h5_file = h5py.File(h5_file, \"r\")\n        self.images = self.h5_file[\"images\"]  # Shape: (N, 32, 32)\n        self.labels = self.h5_file[\"labels\"]  # Shape: (N,)\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n       \n        image = self.images[idx]  \n        image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)  \n\n        label = torch.tensor(self.labels[idx], dtype=torch.long)\n\n        return image, label\nh5_file_path1 = '/kaggle/input/easydata/merged_data (3).h5'  \ndataset1 = SequenceDataset(h5_file_path1)\n\n# Split dataset into training and testing sets (80% for training, 20% for testing)\ntrain_size1 = int(0.8 * len(dataset1))\ntest_size1 = len(dataset1) - train_size1\ntrain_dataset1, test_dataset1 = random_split(dataset1, [train_size1, test_size1])\n\n# Create DataLoaders for batching\ntrain_loader1 = DataLoader(train_dataset1, batch_size=16, shuffle=True)\ntest_loader1 = DataLoader(test_dataset1, batch_size=16, shuffle=False)\n\nprint(\"data loaded succ\")\n\nconfig = ViTConfig(\n    image_size=32,           # Input image size\n    patch_size=1,            # Patch size\n    num_channels=1,          # Grayscale images\n    num_labels=2,            # Number of classes (binary classification)\n    hidden_size=256,         # Hidden size of the transformer\n    num_hidden_layers=6,     # Number of transformer layers\n    num_attention_heads=8,   # Number of attention heads\n    intermediate_size=512,   # Intermediate size in feed-forward layers\n)\n\n# Initialize the model\nmodel = ViTForImageClassification(config)\n\n# Optimizer and loss function\noptimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\ncriterion = nn.CrossEntropyLoss()\n\n# Training function\ndef train_epoch(model, dataloader, optimizer, device):\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n\n    for images, labels in dataloader:\n        images, labels = images.to(device), labels.to(device)\n\n        # Forward pass\n        outputs = model(pixel_values=images)\n        loss = criterion(outputs.logits, labels)\n\n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Update metrics\n        total_loss += loss.item()\n        _, preds = torch.max(outputs.logits, dim=1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\n    avg_loss = total_loss / len(dataloader)\n    accuracy = correct / total\n    return avg_loss, accuracy\n\n# Evaluation function\ndef evaluate(model, dataloader, device):\n    model.eval()\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n\n            # Forward pass\n            outputs = model(pixel_values=images)\n            _, preds = torch.max(outputs.logits, dim=1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n    accuracy = correct / total\n    return accuracy\n# Move model to the device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Training loop\nnum_epochs = 5\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n    train_loss, train_acc = train_epoch(model, train_loader1, optimizer, device)\n    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n\n    test_acc = evaluate(model, test_loader1, device)\n    print(f\"Test Accuracy: {test_acc:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"h5_file_path2 = '/kaggle/input/mediumdata/merged_data (2).h5'  # Update the path if needed\ndataset2 = SequenceDataset(h5_file_path2)\n\n# Split dataset into training and testing sets (80% for training, 20% for testing)\ntrain_size2 = int(0.8 * len(dataset2))\ntest_size2 = len(dataset2) - train_size2\ntrain_dataset2, test_dataset2 = random_split(dataset2, [train_size2, test_size2])\n\n# Create DataLoaders for batching\ntrain_loader2 = DataLoader(train_dataset2, batch_size=16, shuffle=True)\ntest_loader2 = DataLoader(test_dataset2, batch_size=16, shuffle=False)\n\nprint(\" medi data loaded succ\")\n\n\n# Training function\ndef train_epoch(model, dataloader, optimizer, device):\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n\n    for images, labels in dataloader:\n        images, labels = images.to(device), labels.to(device)\n\n        # Forward pass\n        outputs = model(pixel_values=images)\n        loss = criterion(outputs.logits, labels)\n\n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Update metrics\n        total_loss += loss.item()\n        _, preds = torch.max(outputs.logits, dim=1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\n    avg_loss = total_loss / len(dataloader)\n    accuracy = correct / total\n    return avg_loss, accuracy\n\n# Evaluation function\ndef evaluate(model, dataloader, device):\n    model.eval()\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n\n            # Forward pass\n            outputs = model(pixel_values=images)\n            _, preds = torch.max(outputs.logits, dim=1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n    accuracy = correct / total\n    return accuracy\n# Move model to the device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Training loop\nnum_epochs = 5\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n    train_loss, train_acc = train_epoch(model, train_loader2, optimizer, device)\n    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n\n    test_acc = evaluate(model, test_loader2, device)\n    print(f\"Test Accuracy: {test_acc:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"h5_file_path3 = '/kaggle/input/harddata/merged_data (1).h5'  # Update the path if needed\ndataset2 = SequenceDataset(h5_file_path2)\n\n# Split dataset into training and testing sets (80% for training, 20% for testing)\ntrain_size2 = int(0.8 * len(dataset2))\ntest_size2 = len(dataset2) - train_size2\ntrain_dataset2, test_dataset2 = random_split(dataset2, [train_size2, test_size2])\n\n# Create DataLoaders for batching\ntrain_loader2 = DataLoader(train_dataset2, batch_size=16, shuffle=True)\ntest_loader2 = DataLoader(test_dataset2, batch_size=16, shuffle=False)\n\nprint(\"hard data loaded succ\")\n\n# Training function\ndef train_epoch(model, dataloader, optimizer, device):\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n\n    for images, labels in dataloader:\n        images, labels = images.to(device), labels.to(device)\n\n        # Forward pass\n        outputs = model(pixel_values=images)\n        loss = criterion(outputs.logits, labels)\n\n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Update metrics\n        total_loss += loss.item()\n        _, preds = torch.max(outputs.logits, dim=1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\n    avg_loss = total_loss / len(dataloader)\n    accuracy = correct / total\n    return avg_loss, accuracy\n\n# Evaluation function\ndef evaluate(model, dataloader, device):\n    model.eval()\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n\n            # Forward pass\n            outputs = model(pixel_values=images)\n            _, preds = torch.max(outputs.logits, dim=1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n    accuracy = correct / total\n    return accuracy\n# Move model to the device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Training loop\nnum_epochs = 5\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n    train_loss, train_acc = train_epoch(model, train_loader3, optimizer, device)\n    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n\n    test_acc = evaluate(model, test_loader3, device)\n    print(f\"Test Accuracy: {test_acc:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}