{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10142263,"sourceType":"datasetVersion","datasetId":6260074}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport pytorch_lightning as pl\nfrom transformers import BigBirdConfig, BigBirdModel\nimport torch.nn.functional as F\nimport math\n\n\nimport os\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom typing import Optional, Tuple\nfrom pathlib import Path\nimport h5py\n\n\n# Check GPU availability\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"class PathfinderH5Dataset(Dataset):\n    def __init__(self, h5_path):\n        self.h5_path = h5_path\n        with h5py.File(h5_path, 'r') as f:\n            self.length = len(f['images'])\n    \n    def __len__(self):\n        return self.length\n    \n    def __getitem__(self, idx):\n        with h5py.File(self.h5_path, 'r') as f:\n            image = torch.from_numpy(f['images'][idx]).float()\n            label = torch.tensor(f['labels'][idx]).long()\n        \n        image = (image > 127.5).float()\n        directions = self.compute_direction_embeddings(image)\n        pos_emb = self.get_positional_encoding(1024, 256)\n        \n        return {\n            'image': image.view(-1),\n            'directions': directions,\n            'pos_emb': pos_emb,\n            'label': label\n        }\n    \n    def compute_direction_embeddings(self, image):\n        dirs = torch.zeros((32, 32, 8))\n        padded = F.pad(image, (1, 1, 1, 1))\n        directions = [(-1, -1), (-1, 0), (-1, 1), (0, -1), \n                     (0, 1), (1, -1), (1, 0), (1, 1)]\n        \n        for i in range(32):\n            for j in range(32):\n                if image[i, j] > 0:\n                    for d, (di, dj) in enumerate(directions):\n                        dirs[i, j, d] = padded[i+di+1, j+dj+1]\n        return dirs.view(-1, 8)\n    \n    def get_positional_encoding(self, seq_len, d_model):\n        position = torch.arange(seq_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n        pe = torch.zeros(seq_len, d_model)\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        return pe[:, :128]  # Match d_model dimension","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Tokenizer","metadata":{}},{"cell_type":"code","source":"class PathEndpointTokenizer:\n    \"\"\"Adds special tokens for path endpoints and processes images.\"\"\"\n    def __init__(self, max_seq_length=1024):\n        self.max_seq_length = max_seq_length\n        \n    def find_endpoints(self, image):\n        \"\"\"Find the two endpoints in the image.\"\"\"\n        # Find the brightest pixels as endpoints\n        flat_image = image.view(-1)\n        _, indices = torch.topk(flat_image, 2)\n        return indices\n    \n    def add_endpoint_tokens(self, sequence, endpoint_positions):\n        \"\"\"Add special tokens at endpoint positions.\"\"\"\n        sequence = sequence.clone()\n        for pos in endpoint_positions:\n            sequence[pos] = 2.0  # Special value for endpoints\n        return sequence","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class BigBirdPathfinder(pl.LightningModule):\n    def __init__(\n        self,\n        block_size=8,  # Local window size\n        num_random_blocks=2,  # Number of random blocks for global attention\n        attention_probs_dropout_prob=0.2,\n        hidden_dropout_prob=0.2,\n        hidden_size=64,\n        num_attention_heads=2,\n        num_hidden_layers=2\n    ):\n        super().__init__()\n        self.save_hyperparameters()\n        \n        # BigBird configuration\n        self.config = BigBirdConfig(\n            attention_type=\"block_sparse\",\n            block_size=block_size,\n            num_random_blocks=num_random_blocks,\n            max_position_embeddings=1024,  # For 32x32 image\n            attention_probs_dropout_prob=attention_probs_dropout_prob,\n            hidden_dropout_prob=hidden_dropout_prob,\n            hidden_size=hidden_size,\n            num_attention_heads=num_attention_heads,\n            num_hidden_layers=num_hidden_layers\n        )\n        \n        # Initialize BigBird model\n        self.model = BigBirdModel(self.config, add_pooling_layer=False)\n        \n        # Path-specific components\n        self.endpoint_tokenizer = PathEndpointTokenizer()\n        self.path_predictor = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size // 2),\n            nn.GELU(),\n            nn.Dropout(0.1),\n            nn.Linear(hidden_size // 2, 2)  # Binary classification\n        )\n        \n        # Path-aware attention weights\n        self.path_attention_weights = nn.Parameter(torch.ones(num_hidden_layers))\n        \n    def forward(self, batch):\n        images = batch['image']  # [batch_size, 1024]\n        outputs = []\n        \n        for i in range(0, images.size(0), 2):\n            sequence = images[i:i+2]  # Process 2 at a time\n            output = self.model(\n                inputs_embeds=sequence.unsqueeze(-1),  # [2, 1024, 1]\n                position_ids=torch.arange(1024, device=images.device).unsqueeze(0).expand(sequence.size(0), -1),\n                output_hidden_states=True\n            )\n            states = output.last_hidden_state[:, 0]\n            outputs.append(states)\n        \n        outputs = torch.cat(outputs, dim=0)\n        return self.path_predictor(outputs)\n    \n    def training_step(self, batch, batch_idx):\n        logits = self(batch)\n        loss = F.cross_entropy(logits, batch['label'])\n        acc = (logits.argmax(dim=1) == batch['label']).float().mean()\n        \n        # Log metrics\n        self.log('train_loss', loss)\n        self.log('train_acc', acc)\n        \n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        logits = self(batch)\n        loss = F.cross_entropy(logits, batch['label'])\n        acc = (logits.argmax(dim=1) == batch['label']).float().mean()\n        \n        self.log('val_loss', loss)\n        self.log('val_acc', acc)\n        \n        return loss\n    \n    def test_step(self, batch, batch_idx):\n        logits = self(batch)\n        loss = F.cross_entropy(logits, batch['label'])\n        acc = (logits.argmax(dim=1) == batch['label']).float().mean()\n        \n        self.log('test_loss', loss)\n        self.log('test_acc', acc)\n        \n        return loss\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(\n            self.parameters(),\n            lr=1e-4,\n            weight_decay=0.01\n        )\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n            optimizer,\n            T_max=200,\n            eta_min=1e-6\n        )\n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": {\n                \"scheduler\": scheduler,\n                \"monitor\": \"val_loss\"\n            }\n        }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"from torch.utils.tensorboard import SummaryWriter\n\ndef train_progressive_bigbird(max_epochs: int = 20):\n    model = BigBirdPathfinder()  # Initialize at start\n    difficulties = ['easy', 'medium', 'hard']\n    writer = SummaryWriter('runs/bigbird_pathfinder')\n    \n    for difficulty in difficulties:\n        print(f\"\\nTraining on {difficulty} dataset...\")\n        file_path = f'/kaggle/input/bigbird-dataset/merged_data_{difficulty}.h5'\n        \n        with h5py.File(file_path, 'r') as f:\n           total = len(f['images'])\n           train_size = int(0.8 * total)\n           val_size = int(0.1 * total)\n           test_size = total - train_size - val_size\n    \n           indices = torch.randperm(total)\n           train_indices = indices[:train_size]\n           val_indices = indices[train_size:train_size+val_size]\n           test_indices = indices[train_size+val_size:]\n            \n           # Create datasets\n           train_dataset = PathfinderH5Dataset(file_path)\n           val_dataset = PathfinderH5Dataset(file_path)\n           test_dataset = PathfinderH5Dataset(file_path)\n            \n           train_dataset.indices = train_indices\n           val_dataset.indices = val_indices\n           test_dataset.indices = test_indices\n        \n           print(f\"Dataset sizes for {difficulty}:\")\n           print(f\"Total: {total:,}\")\n           print(f\"Train: {train_size:,}\")\n           print(f\"Val: {val_size:,}\")\n           print(f\"Test: {test_size:,}\")\n           \n           # Data stats\n           print(\"\\nPixel Statistics:\")\n           print(f\"Mean: {f['images'][:].mean():.2f}\")\n           print(f\"Std: {f['images'][:].std():.2f}\")\n           print(f\"Connected paths: {(f['labels'][:] == 1).sum():,}\")\n           print(f\"Disconnected paths: {(f['labels'][:] == 0).sum():,}\")\n            \n        train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n        val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)\n        test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)\n        \n        trainer = pl.Trainer(\n            max_epochs=max_epochs,\n            accelerator='gpu',\n            devices=[1],\n            precision=16,\n            callbacks=[\n                pl.callbacks.EarlyStopping(monitor='val_loss', patience=5),\n                pl.callbacks.TQDMProgressBar(refresh_rate=1)\n            ],\n            logger=pl.loggers.TensorBoardLogger('runs', name=f'bigbird_{difficulty}'),\n            accumulate_grad_batches=4,\n            limit_train_batches=0.25,\n            limit_val_batches=0.2\n        )\n        \n        print(f\"\\nStarting training for {difficulty}...\")\n        trainer.fit(model, train_loader, val_loader)\n        test_result = trainer.test(model, test_loader)\n        print(f\"Test results for {difficulty}: {test_result}\")\n        \n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.cuda.empty_cache()\nmodel = train_progressive_bigbird()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%load_ext tensorboard\n%tensorboard --logdir runs/","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}